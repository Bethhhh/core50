---
layout: default
title: {{ site.name }}
---

<div id="home">

<a name="start"></a>

<h1>Continuous Learning Strategies</h1>

While the community has not agreed yet on a shared categorization for CL strategies, here we propose a three-label categorization based on [7] and [10]: <br><br>

<ol class="posts">
      <li><strong>Architectural Strategies</strong>: specific architectures, layers, activation functions, and/or weight-freezing strategies are used to mitigate forgetting. Includes Dual-memories-models attempting to imitate Hippocampus â€“ Cortex duality. </li>
      <li><strong>Regularization Strategies</strong>: the loss function is extended with terms promoting selective consolidation of the weights which are important to retain past memories. Include regularization techniques such as weight sparsification, dropout, early stopping.</li>
      <li><strong>Rehearsal Strategies</strong>: past information is periodically replayed to the model, to strengthen connections for memories it has already learned. A simple approach is storing part of the previous training data and interleaving them with new patterns for future training. A more challenging approach is pseudo-reharshal with generative models. </li>
</ol>

Most of the strategies do not use just one of those approaches but for simplicity we are going to consider them as belonging to just one group. The most popular strategies for each category are listed below. <br><br>


<strong>Architectural Strategies</strong>:<br><br>
<ul class="posts">
      <li><span><i>CopyWeights with Re-init</i> (CWR) <a href=#ref>[1]</a></li>
      <li><span><i>Progressing Neural Networks</i> (PNN) <a href=#ref>[8]</a></li>
</ul>

<strong>Regularization Strategies</strong>:<br><br>
<ul class="posts">
      <li><span><i>Elastic Weights Consolidation</i> (EWC) <a href=#ref>[5]</a></li>
      <li><span><i>Synaptic Intelligence</i> (SynInt) <a href=#ref>[7]</a></li>
      <li><span><i>Learning without Forgetting</i> (LwF) <a href=#ref>[3]</a></li>
</ul>

<strong>Rehearsal Strategies</strong>:<br><br>
<ul class="posts">
      <li><span><i>Incremental Classifier and Representation Learning</i> (iCaRL) <a href=#ref>[6]</a></li>
      <li><span><i>Gradient Episodic Memory</i> (GEM) <a href=#ref>[4]</a></li>
      <li>SOM-STM ??? da capire meglio [10]</li>
</ul>

<h3>Summary Table</h3>

Here we provide a single table from which it is possible to get on which benchmark each strategy has been assessed and where (It would be unfair to report directly the accuracy results since the community has not agreed on a <strong>"model invariant"</strong> evaluation metric yet): <br><br>

 <div id="wrapper">
  
  <table id="keywords" class='keywords' cellspacing="0" cellpadding="0">
    <thead>
      <tr>
        <th>Strategy</th>
        <th>Perm. MNIST</th>
        <th>MNIST Split</th>
        <th>CIFAR Split</th>
        <th>ILSVRC2012 Split</th>
        <th>Atari Games</th>
        <th>CORe50</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="lalign"><strong>CWR</strong></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td><a href=#ref>[1]</a></td>
      </tr>
      <tr>
        <td class="lalign"><strong>PNN</strong></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td><a href=#ref>[8]</a></td>
        <td>-</td>
      </tr>
      <tr>
        <td class="lalign"><strong>EWC</strong></td>
        <td><a href=#ref>[5]</a></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td><a href=#ref>[5]</a></td>
        <td><a href=#ref>[9]</a></td>
      </tr>
      <tr>
        <td class="lalign"><strong>SynInt</strong></td>
        <td><a href=#ref>[7]</a></td>
        <td><a href=#ref>[7]</a></td>
        <td><a href=#ref>[7]</a></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td class="lalign"><strong>iCaRL</strong></td>
        <td>-</td>
        <td>-</td>
        <td><a href=#ref>[6]</a></td>
        <td><a href=#ref>[6]</a></td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td class="lalign"><strong>GEM</strong></td>
        <td><a href=#ref>[4]</a></td>
        <td>-</td>
        <td><a href=#ref>[4]</a></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td class="lalign"><strong>LwF</strong></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td><a href=#ref>[9]</a></td>
      </tr>
    </tbody>
  </table>
 </div> 

 <h3>References</h3>
 <a name="ref"></a>
  <table id='ref_table' style="width:100%">
  <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[1]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Vincenzo Lomonaco and Davide Maltoni. <a href="http://proceedings.mlr.press/v78/lomonaco17a.html" target="_blank">"CORe50: a new Dataset and Benchmark for Continuous Object Recognition".</a> Proceedings of the 1st Annual Conference on Robot Learning, PMLR 78:17-26, 2017. </i></th> 
  </tr>
    <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[2]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>James Kirkpatrick & All. <a href="http://www.pnas.org/content/114/13/3521.abstract" target="_blank">"Overcoming catastrophic forgetting in neural networks".</a> Proceedings of the National Academy of Sciences, 2017, 201611835. </i></th> 
  </tr>
  <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[3]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Li Zhizhong and Derek Hoiem. <a href="http://www.pnas.org/content/114/13/3521.abstract" target="_blank">"Learning without forgetting".</a> European Conference on Computer Vision. Springer International Publishing, 2016. </i></th> 
  </tr>
  <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[4]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Lopez-Paz David and Marc'Aurelio Ranzato. <a href="http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continuum-learning" target="_blank">"Gradient Episodic Memory for Continual Learning".</a> European Conference on Computer Vision. Advances in Neural Information Processing Systems. 2017. </i></th> 
  </tr>
  <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[5]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Kirkpatrick James et al. <a href="http://www.pnas.org/content/114/13/3521.abstract">"Overcoming catastrophic forgetting in neural networks."</a> Proceedings of the National Academy of Sciences, 2017</i></th> 
  </tr>
  <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[6]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Rebuffi Sylvestre-Alvise, Alexander Kolesnikov and Christoph H. Lampert. <a href='https://arxiv.org/abs/1611.07725'>"iCaRL: Incremental classifier and representation learning."</a> arXiv preprint arXiv:1611.07725, 2016.</i></th> 
  </tr>
 <tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[7]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Zenke, Friedemann, Ben Poole, and Surya Ganguli. <a href='http://proceedings.mlr.press/v70/zenke17a.html'>"Continual learning through synaptic intelligence". </a> International Conference on Machine Learning. 2017.</i></th> 
  </tr>
<tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[8]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Rusu Andrei et al. <a href='https://arxiv.org/abs/1606.04671'>"Progressive neural networks."</a> arXiv preprint arXiv:1606.04671, 2016.</i></th> 
  </tr>
<tr>
    <th style='font-weight: normal; border: 0px; text-align: left;
    vertical-align: top;'>[9]</th>
    <th style='font-weight: normal; border: 0px; text-align: left; padding-left:3px'><i>Vincenzo Lomonaco and Davide Maltoni. <a href='https://vlomonaco.github.io/core50/leaderboard'> CORe50 LeaderBoard</a>. Website, 2017.</i></th> 
  </tr>

</table>
